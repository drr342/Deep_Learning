python /home/drr342/dl/assignments/hw3/examples/word_language_model/main.py --data /home/drr342/dl/assignments/hw3/examples/word_language_model/data/wikitext-2 --save /home/drr342/dl/assignments/hw3/models/GRU'_'400'_'1'_'32.pt --cuda --model GRU --epochs 10 --emsize 400 --nlayers 1 --bptt 32

/home/drr342/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
| epoch   1 |   200/ 3263 batches | lr 20.00 | ms/batch 39.63 | loss  7.92 | ppl  2744.42
| epoch   1 |   400/ 3263 batches | lr 20.00 | ms/batch 38.79 | loss  6.68 | ppl   796.11
| epoch   1 |   600/ 3263 batches | lr 20.00 | ms/batch 38.82 | loss  6.29 | ppl   537.21
| epoch   1 |   800/ 3263 batches | lr 20.00 | ms/batch 38.76 | loss  6.04 | ppl   417.87
| epoch   1 |  1000/ 3263 batches | lr 20.00 | ms/batch 38.83 | loss  5.97 | ppl   392.79
| epoch   1 |  1200/ 3263 batches | lr 20.00 | ms/batch 38.94 | loss  5.88 | ppl   359.15
| epoch   1 |  1400/ 3263 batches | lr 20.00 | ms/batch 38.92 | loss  5.84 | ppl   344.36
| epoch   1 |  1600/ 3263 batches | lr 20.00 | ms/batch 38.99 | loss  5.77 | ppl   321.49
| epoch   1 |  1800/ 3263 batches | lr 20.00 | ms/batch 38.98 | loss  5.79 | ppl   326.11
| epoch   1 |  2000/ 3263 batches | lr 20.00 | ms/batch 39.00 | loss  5.66 | ppl   286.39
| epoch   1 |  2200/ 3263 batches | lr 20.00 | ms/batch 39.06 | loss  5.63 | ppl   279.10
| epoch   1 |  2400/ 3263 batches | lr 20.00 | ms/batch 39.06 | loss  5.55 | ppl   256.87
| epoch   1 |  2600/ 3263 batches | lr 20.00 | ms/batch 39.05 | loss  5.56 | ppl   259.06
| epoch   1 |  2800/ 3263 batches | lr 20.00 | ms/batch 39.00 | loss  5.55 | ppl   256.83
| epoch   1 |  3000/ 3263 batches | lr 20.00 | ms/batch 38.94 | loss  5.51 | ppl   248.22
| epoch   1 |  3200/ 3263 batches | lr 20.00 | ms/batch 39.00 | loss  5.43 | ppl   228.08
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 131.78s | valid loss  5.44 | valid ppl   230.41
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 3263 batches | lr 20.00 | ms/batch 37.95 | loss  5.47 | ppl   237.04
| epoch   2 |   400/ 3263 batches | lr 20.00 | ms/batch 37.82 | loss  5.44 | ppl   231.35
| epoch   2 |   600/ 3263 batches | lr 20.00 | ms/batch 37.79 | loss  5.31 | ppl   203.21
| epoch   2 |   800/ 3263 batches | lr 20.00 | ms/batch 37.89 | loss  5.20 | ppl   181.19
| epoch   2 |  1000/ 3263 batches | lr 20.00 | ms/batch 37.91 | loss  5.26 | ppl   193.14
| epoch   2 |  1200/ 3263 batches | lr 20.00 | ms/batch 37.88 | loss  5.20 | ppl   181.25
| epoch   2 |  1400/ 3263 batches | lr 20.00 | ms/batch 38.04 | loss  5.26 | ppl   192.03
| epoch   2 |  1600/ 3263 batches | lr 20.00 | ms/batch 38.06 | loss  5.23 | ppl   186.02
| epoch   2 |  1800/ 3263 batches | lr 20.00 | ms/batch 38.03 | loss  5.27 | ppl   194.73
| epoch   2 |  2000/ 3263 batches | lr 20.00 | ms/batch 38.10 | loss  5.18 | ppl   178.14
| epoch   2 |  2200/ 3263 batches | lr 20.00 | ms/batch 38.16 | loss  5.18 | ppl   176.82
| epoch   2 |  2400/ 3263 batches | lr 20.00 | ms/batch 38.11 | loss  5.09 | ppl   162.72
| epoch   2 |  2600/ 3263 batches | lr 20.00 | ms/batch 38.06 | loss  5.11 | ppl   166.25
| epoch   2 |  2800/ 3263 batches | lr 20.00 | ms/batch 38.17 | loss  5.12 | ppl   167.61
| epoch   2 |  3000/ 3263 batches | lr 20.00 | ms/batch 38.13 | loss  5.11 | ppl   166.33
| epoch   2 |  3200/ 3263 batches | lr 20.00 | ms/batch 38.17 | loss  5.05 | ppl   156.16
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 128.65s | valid loss  5.28 | valid ppl   196.64
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 3263 batches | lr 20.00 | ms/batch 38.33 | loss  5.13 | ppl   168.67
| epoch   3 |   400/ 3263 batches | lr 20.00 | ms/batch 38.27 | loss  5.13 | ppl   169.17
| epoch   3 |   600/ 3263 batches | lr 20.00 | ms/batch 38.23 | loss  5.01 | ppl   150.05
| epoch   3 |   800/ 3263 batches | lr 20.00 | ms/batch 38.26 | loss  4.93 | ppl   138.06
| epoch   3 |  1000/ 3263 batches | lr 20.00 | ms/batch 38.26 | loss  5.01 | ppl   150.35
| epoch   3 |  1200/ 3263 batches | lr 20.00 | ms/batch 38.26 | loss  4.95 | ppl   141.58
| epoch   3 |  1400/ 3263 batches | lr 20.00 | ms/batch 38.18 | loss  5.03 | ppl   153.07
| epoch   3 |  1600/ 3263 batches | lr 20.00 | ms/batch 38.28 | loss  4.99 | ppl   147.07
| epoch   3 |  1800/ 3263 batches | lr 20.00 | ms/batch 38.25 | loss  5.05 | ppl   156.71
| epoch   3 |  2000/ 3263 batches | lr 20.00 | ms/batch 38.25 | loss  4.98 | ppl   144.76
| epoch   3 |  2200/ 3263 batches | lr 20.00 | ms/batch 38.18 | loss  4.97 | ppl   144.01
| epoch   3 |  2400/ 3263 batches | lr 20.00 | ms/batch 38.27 | loss  4.87 | ppl   130.58
| epoch   3 |  2600/ 3263 batches | lr 20.00 | ms/batch 38.28 | loss  4.91 | ppl   135.52
| epoch   3 |  2800/ 3263 batches | lr 20.00 | ms/batch 38.20 | loss  4.92 | ppl   136.54
| epoch   3 |  3000/ 3263 batches | lr 20.00 | ms/batch 38.25 | loss  4.93 | ppl   137.91
| epoch   3 |  3200/ 3263 batches | lr 20.00 | ms/batch 38.29 | loss  4.87 | ppl   129.81
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 129.42s | valid loss  5.24 | valid ppl   188.44
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 3263 batches | lr 20.00 | ms/batch 38.37 | loss  4.95 | ppl   140.62
| epoch   4 |   400/ 3263 batches | lr 20.00 | ms/batch 38.21 | loss  4.95 | ppl   141.77
| epoch   4 |   600/ 3263 batches | lr 20.00 | ms/batch 38.28 | loss  4.84 | ppl   126.78
| epoch   4 |   800/ 3263 batches | lr 20.00 | ms/batch 38.35 | loss  4.77 | ppl   117.52
| epoch   4 |  1000/ 3263 batches | lr 20.00 | ms/batch 38.38 | loss  4.86 | ppl   128.93
| epoch   4 |  1200/ 3263 batches | lr 20.00 | ms/batch 38.36 | loss  4.81 | ppl   122.72
| epoch   4 |  1400/ 3263 batches | lr 20.00 | ms/batch 38.43 | loss  4.90 | ppl   134.00
| epoch   4 |  1600/ 3263 batches | lr 20.00 | ms/batch 38.42 | loss  4.86 | ppl   128.95
| epoch   4 |  1800/ 3263 batches | lr 20.00 | ms/batch 38.34 | loss  4.92 | ppl   136.61
| epoch   4 |  2000/ 3263 batches | lr 20.00 | ms/batch 38.38 | loss  4.85 | ppl   127.78
| epoch   4 |  2200/ 3263 batches | lr 20.00 | ms/batch 38.39 | loss  4.85 | ppl   127.35
| epoch   4 |  2400/ 3263 batches | lr 20.00 | ms/batch 38.46 | loss  4.74 | ppl   114.31
| epoch   4 |  2600/ 3263 batches | lr 20.00 | ms/batch 38.34 | loss  4.78 | ppl   119.58
| epoch   4 |  2800/ 3263 batches | lr 20.00 | ms/batch 38.30 | loss  4.79 | ppl   120.82
| epoch   4 |  3000/ 3263 batches | lr 20.00 | ms/batch 38.37 | loss  4.80 | ppl   121.73
| epoch   4 |  3200/ 3263 batches | lr 20.00 | ms/batch 38.34 | loss  4.74 | ppl   114.38
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 129.77s | valid loss  5.21 | valid ppl   183.33
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 3263 batches | lr 20.00 | ms/batch 39.84 | loss  4.82 | ppl   123.42
| epoch   5 |   400/ 3263 batches | lr 20.00 | ms/batch 39.56 | loss  4.84 | ppl   126.23
| epoch   5 |   600/ 3263 batches | lr 20.00 | ms/batch 39.44 | loss  4.73 | ppl   113.52
| epoch   5 |   800/ 3263 batches | lr 20.00 | ms/batch 39.58 | loss  4.65 | ppl   104.21
| epoch   5 |  1000/ 3263 batches | lr 20.00 | ms/batch 39.52 | loss  4.75 | ppl   116.00
| epoch   5 |  1200/ 3263 batches | lr 20.00 | ms/batch 39.64 | loss  4.71 | ppl   110.81
| epoch   5 |  1400/ 3263 batches | lr 20.00 | ms/batch 39.62 | loss  4.81 | ppl   122.30
| epoch   5 |  1600/ 3263 batches | lr 20.00 | ms/batch 39.57 | loss  4.76 | ppl   116.20
| epoch   5 |  1800/ 3263 batches | lr 20.00 | ms/batch 39.67 | loss  4.82 | ppl   123.85
| epoch   5 |  2000/ 3263 batches | lr 20.00 | ms/batch 39.60 | loss  4.76 | ppl   116.68
| epoch   5 |  2200/ 3263 batches | lr 20.00 | ms/batch 39.61 | loss  4.76 | ppl   116.67
| epoch   5 |  2400/ 3263 batches | lr 20.00 | ms/batch 39.64 | loss  4.64 | ppl   103.78
| epoch   5 |  2600/ 3263 batches | lr 20.00 | ms/batch 39.61 | loss  4.69 | ppl   108.47
| epoch   5 |  2800/ 3263 batches | lr 20.00 | ms/batch 39.60 | loss  4.71 | ppl   111.05
| epoch   5 |  3000/ 3263 batches | lr 20.00 | ms/batch 39.56 | loss  4.73 | ppl   113.80
| epoch   5 |  3200/ 3263 batches | lr 20.00 | ms/batch 39.60 | loss  4.72 | ppl   112.72
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 133.83s | valid loss  5.25 | valid ppl   191.49
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 3263 batches | lr 5.00 | ms/batch 38.45 | loss  4.75 | ppl   115.27
| epoch   6 |   400/ 3263 batches | lr 5.00 | ms/batch 38.21 | loss  4.70 | ppl   109.42
| epoch   6 |   600/ 3263 batches | lr 5.00 | ms/batch 38.09 | loss  4.54 | ppl    94.07
| epoch   6 |   800/ 3263 batches | lr 5.00 | ms/batch 38.18 | loss  4.45 | ppl    85.22
| epoch   6 |  1000/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.51 | ppl    91.11
| epoch   6 |  1200/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.43 | ppl    84.23
| epoch   6 |  1400/ 3263 batches | lr 5.00 | ms/batch 38.19 | loss  4.50 | ppl    89.78
| epoch   6 |  1600/ 3263 batches | lr 5.00 | ms/batch 38.24 | loss  4.42 | ppl    82.99
| epoch   6 |  1800/ 3263 batches | lr 5.00 | ms/batch 38.27 | loss  4.46 | ppl    86.72
| epoch   6 |  2000/ 3263 batches | lr 5.00 | ms/batch 38.28 | loss  4.38 | ppl    79.65
| epoch   6 |  2200/ 3263 batches | lr 5.00 | ms/batch 38.40 | loss  4.36 | ppl    78.58
| epoch   6 |  2400/ 3263 batches | lr 5.00 | ms/batch 38.33 | loss  4.21 | ppl    67.59
| epoch   6 |  2600/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.24 | ppl    69.63
| epoch   6 |  2800/ 3263 batches | lr 5.00 | ms/batch 38.34 | loss  4.23 | ppl    68.90
| epoch   6 |  3000/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.26 | ppl    70.53
| epoch   6 |  3200/ 3263 batches | lr 5.00 | ms/batch 38.32 | loss  4.21 | ppl    67.40
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 129.50s | valid loss  4.98 | valid ppl   145.50
-----------------------------------------------------------------------------------------
| epoch   7 |   200/ 3263 batches | lr 5.00 | ms/batch 38.51 | loss  4.43 | ppl    84.24
| epoch   7 |   400/ 3263 batches | lr 5.00 | ms/batch 38.39 | loss  4.44 | ppl    84.52
| epoch   7 |   600/ 3263 batches | lr 5.00 | ms/batch 38.44 | loss  4.31 | ppl    74.30
| epoch   7 |   800/ 3263 batches | lr 5.00 | ms/batch 38.32 | loss  4.24 | ppl    69.09
| epoch   7 |  1000/ 3263 batches | lr 5.00 | ms/batch 38.43 | loss  4.32 | ppl    75.49
| epoch   7 |  1200/ 3263 batches | lr 5.00 | ms/batch 38.44 | loss  4.26 | ppl    71.06
| epoch   7 |  1400/ 3263 batches | lr 5.00 | ms/batch 38.36 | loss  4.34 | ppl    76.94
| epoch   7 |  1600/ 3263 batches | lr 5.00 | ms/batch 38.39 | loss  4.28 | ppl    72.16
| epoch   7 |  1800/ 3263 batches | lr 5.00 | ms/batch 38.39 | loss  4.34 | ppl    76.40
| epoch   7 |  2000/ 3263 batches | lr 5.00 | ms/batch 38.34 | loss  4.26 | ppl    70.96
| epoch   7 |  2200/ 3263 batches | lr 5.00 | ms/batch 38.39 | loss  4.25 | ppl    70.37
| epoch   7 |  2400/ 3263 batches | lr 5.00 | ms/batch 38.33 | loss  4.12 | ppl    61.42
| epoch   7 |  2600/ 3263 batches | lr 5.00 | ms/batch 38.34 | loss  4.15 | ppl    63.53
| epoch   7 |  2800/ 3263 batches | lr 5.00 | ms/batch 38.35 | loss  4.16 | ppl    63.89
| epoch   7 |  3000/ 3263 batches | lr 5.00 | ms/batch 38.33 | loss  4.18 | ppl    65.68
| epoch   7 |  3200/ 3263 batches | lr 5.00 | ms/batch 38.29 | loss  4.15 | ppl    63.24
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 129.83s | valid loss  4.97 | valid ppl   143.51
-----------------------------------------------------------------------------------------
| epoch   8 |   200/ 3263 batches | lr 5.00 | ms/batch 38.48 | loss  4.33 | ppl    75.87
| epoch   8 |   400/ 3263 batches | lr 5.00 | ms/batch 38.32 | loss  4.34 | ppl    76.57
| epoch   8 |   600/ 3263 batches | lr 5.00 | ms/batch 38.29 | loss  4.21 | ppl    67.45
| epoch   8 |   800/ 3263 batches | lr 5.00 | ms/batch 38.31 | loss  4.14 | ppl    62.93
| epoch   8 |  1000/ 3263 batches | lr 5.00 | ms/batch 38.21 | loss  4.23 | ppl    68.97
| epoch   8 |  1200/ 3263 batches | lr 5.00 | ms/batch 38.24 | loss  4.18 | ppl    65.54
| epoch   8 |  1400/ 3263 batches | lr 5.00 | ms/batch 38.20 | loss  4.26 | ppl    70.65
| epoch   8 |  1600/ 3263 batches | lr 5.00 | ms/batch 38.27 | loss  4.20 | ppl    66.48
| epoch   8 |  1800/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.26 | ppl    70.71
| epoch   8 |  2000/ 3263 batches | lr 5.00 | ms/batch 38.21 | loss  4.19 | ppl    66.18
| epoch   8 |  2200/ 3263 batches | lr 5.00 | ms/batch 38.27 | loss  4.19 | ppl    65.82
| epoch   8 |  2400/ 3263 batches | lr 5.00 | ms/batch 38.30 | loss  4.06 | ppl    57.89
| epoch   8 |  2600/ 3263 batches | lr 5.00 | ms/batch 38.18 | loss  4.09 | ppl    59.69
| epoch   8 |  2800/ 3263 batches | lr 5.00 | ms/batch 38.19 | loss  4.10 | ppl    60.52
| epoch   8 |  3000/ 3263 batches | lr 5.00 | ms/batch 38.36 | loss  4.13 | ppl    62.30
| epoch   8 |  3200/ 3263 batches | lr 5.00 | ms/batch 38.26 | loss  4.09 | ppl    59.65
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 129.48s | valid loss  4.96 | valid ppl   143.23
-----------------------------------------------------------------------------------------
| epoch   9 |   200/ 3263 batches | lr 5.00 | ms/batch 39.91 | loss  4.25 | ppl    70.21
| epoch   9 |   400/ 3263 batches | lr 5.00 | ms/batch 39.70 | loss  4.26 | ppl    70.85
| epoch   9 |   600/ 3263 batches | lr 5.00 | ms/batch 39.71 | loss  4.14 | ppl    62.90
| epoch   9 |   800/ 3263 batches | lr 5.00 | ms/batch 39.71 | loss  4.08 | ppl    58.92
| epoch   9 |  1000/ 3263 batches | lr 5.00 | ms/batch 39.73 | loss  4.17 | ppl    64.72
| epoch   9 |  1200/ 3263 batches | lr 5.00 | ms/batch 39.70 | loss  4.12 | ppl    61.40
| epoch   9 |  1400/ 3263 batches | lr 5.00 | ms/batch 39.64 | loss  4.20 | ppl    66.37
| epoch   9 |  1600/ 3263 batches | lr 5.00 | ms/batch 39.74 | loss  4.14 | ppl    62.89
| epoch   9 |  1800/ 3263 batches | lr 5.00 | ms/batch 39.72 | loss  4.20 | ppl    66.92
| epoch   9 |  2000/ 3263 batches | lr 5.00 | ms/batch 39.72 | loss  4.14 | ppl    62.92
| epoch   9 |  2200/ 3263 batches | lr 5.00 | ms/batch 39.74 | loss  4.13 | ppl    62.20
| epoch   9 |  2400/ 3263 batches | lr 5.00 | ms/batch 39.76 | loss  4.00 | ppl    54.83
| epoch   9 |  2600/ 3263 batches | lr 5.00 | ms/batch 39.67 | loss  4.04 | ppl    57.09
| epoch   9 |  2800/ 3263 batches | lr 5.00 | ms/batch 39.69 | loss  4.05 | ppl    57.39
| epoch   9 |  3000/ 3263 batches | lr 5.00 | ms/batch 39.78 | loss  4.08 | ppl    59.39
| epoch   9 |  3200/ 3263 batches | lr 5.00 | ms/batch 39.60 | loss  4.04 | ppl    56.78
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 134.23s | valid loss  4.97 | valid ppl   143.75
-----------------------------------------------------------------------------------------
| epoch  10 |   200/ 3263 batches | lr 1.25 | ms/batch 38.54 | loss  4.24 | ppl    69.53
| epoch  10 |   400/ 3263 batches | lr 1.25 | ms/batch 38.44 | loss  4.26 | ppl    70.68
| epoch  10 |   600/ 3263 batches | lr 1.25 | ms/batch 38.39 | loss  4.13 | ppl    61.97
| epoch  10 |   800/ 3263 batches | lr 1.25 | ms/batch 38.40 | loss  4.06 | ppl    57.95
| epoch  10 |  1000/ 3263 batches | lr 1.25 | ms/batch 38.34 | loss  4.14 | ppl    63.01
| epoch  10 |  1200/ 3263 batches | lr 1.25 | ms/batch 38.45 | loss  4.08 | ppl    59.35
| epoch  10 |  1400/ 3263 batches | lr 1.25 | ms/batch 38.35 | loss  4.15 | ppl    63.42
| epoch  10 |  1600/ 3263 batches | lr 1.25 | ms/batch 38.29 | loss  4.08 | ppl    59.12
| epoch  10 |  1800/ 3263 batches | lr 1.25 | ms/batch 38.34 | loss  4.14 | ppl    62.58
| epoch  10 |  2000/ 3263 batches | lr 1.25 | ms/batch 38.27 | loss  4.06 | ppl    58.05
| epoch  10 |  2200/ 3263 batches | lr 1.25 | ms/batch 38.40 | loss  4.06 | ppl    57.92
| epoch  10 |  2400/ 3263 batches | lr 1.25 | ms/batch 38.37 | loss  3.91 | ppl    49.92
| epoch  10 |  2600/ 3263 batches | lr 1.25 | ms/batch 38.36 | loss  3.95 | ppl    51.80
| epoch  10 |  2800/ 3263 batches | lr 1.25 | ms/batch 38.26 | loss  3.93 | ppl    51.13
| epoch  10 |  3000/ 3263 batches | lr 1.25 | ms/batch 38.23 | loss  3.96 | ppl    52.44
| epoch  10 |  3200/ 3263 batches | lr 1.25 | ms/batch 38.36 | loss  3.91 | ppl    50.00
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 129.78s | valid loss  4.90 | valid ppl   134.28
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  4.83 | test ppl   125.69
=========================================================================================
