python /home/drr342/dl/assignments/hw3/examples/word_language_model/main.py --data /home/drr342/dl/assignments/hw3/examples/word_language_model/data/wikitext-2 --save /home/drr342/dl/assignments/hw3/models/GRU'_'100'_'1'_'32.pt --cuda --model GRU --epochs 10 --emsize 100 --nlayers 1 --bptt 32

/home/drr342/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
| epoch   1 |   200/ 3263 batches | lr 20.00 | ms/batch 36.69 | loss  8.04 | ppl  3095.58
| epoch   1 |   400/ 3263 batches | lr 20.00 | ms/batch 35.82 | loss  6.80 | ppl   894.12
| epoch   1 |   600/ 3263 batches | lr 20.00 | ms/batch 35.52 | loss  6.36 | ppl   579.70
| epoch   1 |   800/ 3263 batches | lr 20.00 | ms/batch 35.24 | loss  6.10 | ppl   446.71
| epoch   1 |  1000/ 3263 batches | lr 20.00 | ms/batch 36.02 | loss  6.04 | ppl   421.40
| epoch   1 |  1200/ 3263 batches | lr 20.00 | ms/batch 36.21 | loss  5.95 | ppl   381.90
| epoch   1 |  1400/ 3263 batches | lr 20.00 | ms/batch 34.79 | loss  5.91 | ppl   366.93
| epoch   1 |  1600/ 3263 batches | lr 20.00 | ms/batch 36.68 | loss  5.84 | ppl   342.31
| epoch   1 |  1800/ 3263 batches | lr 20.00 | ms/batch 35.78 | loss  5.84 | ppl   345.13
| epoch   1 |  2000/ 3263 batches | lr 20.00 | ms/batch 36.33 | loss  5.73 | ppl   307.80
| epoch   1 |  2200/ 3263 batches | lr 20.00 | ms/batch 34.91 | loss  5.70 | ppl   298.76
| epoch   1 |  2400/ 3263 batches | lr 20.00 | ms/batch 34.96 | loss  5.62 | ppl   275.58
| epoch   1 |  2600/ 3263 batches | lr 20.00 | ms/batch 35.43 | loss  5.63 | ppl   279.91
| epoch   1 |  2800/ 3263 batches | lr 20.00 | ms/batch 35.48 | loss  5.62 | ppl   275.96
| epoch   1 |  3000/ 3263 batches | lr 20.00 | ms/batch 35.05 | loss  5.58 | ppl   264.23
| epoch   1 |  3200/ 3263 batches | lr 20.00 | ms/batch 34.53 | loss  5.50 | ppl   245.82
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 120.83s | valid loss  5.49 | valid ppl   243.22
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 3263 batches | lr 20.00 | ms/batch 36.65 | loss  5.56 | ppl   258.79
| epoch   2 |   400/ 3263 batches | lr 20.00 | ms/batch 35.52 | loss  5.54 | ppl   254.14
| epoch   2 |   600/ 3263 batches | lr 20.00 | ms/batch 34.57 | loss  5.41 | ppl   224.15
| epoch   2 |   800/ 3263 batches | lr 20.00 | ms/batch 34.54 | loss  5.29 | ppl   197.52
| epoch   2 |  1000/ 3263 batches | lr 20.00 | ms/batch 34.50 | loss  5.36 | ppl   212.87
| epoch   2 |  1200/ 3263 batches | lr 20.00 | ms/batch 34.41 | loss  5.30 | ppl   200.59
| epoch   2 |  1400/ 3263 batches | lr 20.00 | ms/batch 34.40 | loss  5.36 | ppl   213.11
| epoch   2 |  1600/ 3263 batches | lr 20.00 | ms/batch 34.36 | loss  5.33 | ppl   205.75
| epoch   2 |  1800/ 3263 batches | lr 20.00 | ms/batch 34.30 | loss  5.37 | ppl   215.04
| epoch   2 |  2000/ 3263 batches | lr 20.00 | ms/batch 34.31 | loss  5.29 | ppl   198.22
| epoch   2 |  2200/ 3263 batches | lr 20.00 | ms/batch 34.29 | loss  5.28 | ppl   196.22
| epoch   2 |  2400/ 3263 batches | lr 20.00 | ms/batch 34.25 | loss  5.21 | ppl   182.21
| epoch   2 |  2600/ 3263 batches | lr 20.00 | ms/batch 34.19 | loss  5.22 | ppl   185.70
| epoch   2 |  2800/ 3263 batches | lr 20.00 | ms/batch 34.16 | loss  5.23 | ppl   186.06
| epoch   2 |  3000/ 3263 batches | lr 20.00 | ms/batch 34.15 | loss  5.23 | ppl   186.30
| epoch   2 |  3200/ 3263 batches | lr 20.00 | ms/batch 34.09 | loss  5.15 | ppl   172.26
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 117.09s | valid loss  5.34 | valid ppl   208.75
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 3263 batches | lr 20.00 | ms/batch 35.46 | loss  5.24 | ppl   188.07
| epoch   3 |   400/ 3263 batches | lr 20.00 | ms/batch 35.19 | loss  5.25 | ppl   190.64
| epoch   3 |   600/ 3263 batches | lr 20.00 | ms/batch 35.18 | loss  5.14 | ppl   171.35
| epoch   3 |   800/ 3263 batches | lr 20.00 | ms/batch 35.23 | loss  5.04 | ppl   155.17
| epoch   3 |  1000/ 3263 batches | lr 20.00 | ms/batch 35.19 | loss  5.13 | ppl   169.64
| epoch   3 |  1200/ 3263 batches | lr 20.00 | ms/batch 35.17 | loss  5.08 | ppl   160.97
| epoch   3 |  1400/ 3263 batches | lr 20.00 | ms/batch 35.14 | loss  5.16 | ppl   174.31
| epoch   3 |  1600/ 3263 batches | lr 20.00 | ms/batch 35.13 | loss  5.13 | ppl   168.46
| epoch   3 |  1800/ 3263 batches | lr 20.00 | ms/batch 35.13 | loss  5.18 | ppl   177.66
| epoch   3 |  2000/ 3263 batches | lr 20.00 | ms/batch 35.13 | loss  5.11 | ppl   165.19
| epoch   3 |  2200/ 3263 batches | lr 20.00 | ms/batch 35.10 | loss  5.11 | ppl   165.67
| epoch   3 |  2400/ 3263 batches | lr 20.00 | ms/batch 35.11 | loss  5.02 | ppl   152.11
| epoch   3 |  2600/ 3263 batches | lr 20.00 | ms/batch 35.08 | loss  5.04 | ppl   154.18
| epoch   3 |  2800/ 3263 batches | lr 20.00 | ms/batch 35.04 | loss  5.05 | ppl   156.16
| epoch   3 |  3000/ 3263 batches | lr 20.00 | ms/batch 35.08 | loss  5.06 | ppl   158.00
| epoch   3 |  3200/ 3263 batches | lr 20.00 | ms/batch 35.07 | loss  4.99 | ppl   146.42
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 119.08s | valid loss  5.30 | valid ppl   199.62
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 3263 batches | lr 20.00 | ms/batch 33.97 | loss  5.08 | ppl   160.36
| epoch   4 |   400/ 3263 batches | lr 20.00 | ms/batch 33.80 | loss  5.10 | ppl   163.60
| epoch   4 |   600/ 3263 batches | lr 20.00 | ms/batch 33.79 | loss  5.00 | ppl   147.88
| epoch   4 |   800/ 3263 batches | lr 20.00 | ms/batch 33.75 | loss  4.92 | ppl   137.15
| epoch   4 |  1000/ 3263 batches | lr 20.00 | ms/batch 33.78 | loss  5.02 | ppl   151.71
| epoch   4 |  1200/ 3263 batches | lr 20.00 | ms/batch 33.68 | loss  4.97 | ppl   143.40
| epoch   4 |  1400/ 3263 batches | lr 20.00 | ms/batch 33.72 | loss  5.06 | ppl   157.33
| epoch   4 |  1600/ 3263 batches | lr 20.00 | ms/batch 33.67 | loss  5.03 | ppl   153.60
| epoch   4 |  1800/ 3263 batches | lr 20.00 | ms/batch 33.67 | loss  5.08 | ppl   160.81
| epoch   4 |  2000/ 3263 batches | lr 20.00 | ms/batch 33.66 | loss  5.02 | ppl   150.83
| epoch   4 |  2200/ 3263 batches | lr 20.00 | ms/batch 33.75 | loss  5.03 | ppl   153.22
| epoch   4 |  2400/ 3263 batches | lr 20.00 | ms/batch 34.38 | loss  4.94 | ppl   139.11
| epoch   4 |  2600/ 3263 batches | lr 20.00 | ms/batch 33.92 | loss  4.96 | ppl   142.24
| epoch   4 |  2800/ 3263 batches | lr 20.00 | ms/batch 33.90 | loss  4.99 | ppl   146.35
| epoch   4 |  3000/ 3263 batches | lr 20.00 | ms/batch 33.94 | loss  5.03 | ppl   152.97
| epoch   4 |  3200/ 3263 batches | lr 20.00 | ms/batch 34.44 | loss  4.97 | ppl   144.17
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 114.88s | valid loss  5.31 | valid ppl   201.58
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 3263 batches | lr 5.00 | ms/batch 34.23 | loss  5.00 | ppl   149.07
| epoch   5 |   400/ 3263 batches | lr 5.00 | ms/batch 34.08 | loss  4.95 | ppl   141.12
| epoch   5 |   600/ 3263 batches | lr 5.00 | ms/batch 34.12 | loss  4.81 | ppl   122.51
| epoch   5 |   800/ 3263 batches | lr 5.00 | ms/batch 34.17 | loss  4.72 | ppl   111.79
| epoch   5 |  1000/ 3263 batches | lr 5.00 | ms/batch 34.17 | loss  4.78 | ppl   119.17
| epoch   5 |  1200/ 3263 batches | lr 5.00 | ms/batch 34.19 | loss  4.70 | ppl   109.74
| epoch   5 |  1400/ 3263 batches | lr 5.00 | ms/batch 34.25 | loss  4.77 | ppl   118.16
| epoch   5 |  1600/ 3263 batches | lr 5.00 | ms/batch 34.74 | loss  4.71 | ppl   110.50
| epoch   5 |  1800/ 3263 batches | lr 5.00 | ms/batch 34.29 | loss  4.75 | ppl   115.61
| epoch   5 |  2000/ 3263 batches | lr 5.00 | ms/batch 34.32 | loss  4.66 | ppl   105.90
| epoch   5 |  2200/ 3263 batches | lr 5.00 | ms/batch 34.40 | loss  4.66 | ppl   105.69
| epoch   5 |  2400/ 3263 batches | lr 5.00 | ms/batch 34.45 | loss  4.54 | ppl    93.47
| epoch   5 |  2600/ 3263 batches | lr 5.00 | ms/batch 34.44 | loss  4.54 | ppl    93.85
| epoch   5 |  2800/ 3263 batches | lr 5.00 | ms/batch 34.43 | loss  4.55 | ppl    94.64
| epoch   5 |  3000/ 3263 batches | lr 5.00 | ms/batch 34.50 | loss  4.57 | ppl    96.14
| epoch   5 |  3200/ 3263 batches | lr 5.00 | ms/batch 34.48 | loss  4.48 | ppl    88.21
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 116.47s | valid loss  5.02 | valid ppl   150.67
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 3263 batches | lr 5.00 | ms/batch 34.70 | loss  4.71 | ppl   111.24
| epoch   6 |   400/ 3263 batches | lr 5.00 | ms/batch 34.61 | loss  4.71 | ppl   110.96
| epoch   6 |   600/ 3263 batches | lr 5.00 | ms/batch 34.61 | loss  4.60 | ppl    99.21
| epoch   6 |   800/ 3263 batches | lr 5.00 | ms/batch 34.63 | loss  4.52 | ppl    92.22
| epoch   6 |  1000/ 3263 batches | lr 5.00 | ms/batch 34.62 | loss  4.61 | ppl    99.99
| epoch   6 |  1200/ 3263 batches | lr 5.00 | ms/batch 34.65 | loss  4.54 | ppl    94.16
| epoch   6 |  1400/ 3263 batches | lr 5.00 | ms/batch 34.62 | loss  4.63 | ppl   102.70
| epoch   6 |  1600/ 3263 batches | lr 5.00 | ms/batch 34.63 | loss  4.58 | ppl    97.39
| epoch   6 |  1800/ 3263 batches | lr 5.00 | ms/batch 34.60 | loss  4.64 | ppl   103.20
| epoch   6 |  2000/ 3263 batches | lr 5.00 | ms/batch 34.70 | loss  4.56 | ppl    95.18
| epoch   6 |  2200/ 3263 batches | lr 5.00 | ms/batch 34.65 | loss  4.56 | ppl    96.04
| epoch   6 |  2400/ 3263 batches | lr 5.00 | ms/batch 34.68 | loss  4.45 | ppl    85.33
| epoch   6 |  2600/ 3263 batches | lr 5.00 | ms/batch 34.65 | loss  4.46 | ppl    86.64
| epoch   6 |  2800/ 3263 batches | lr 5.00 | ms/batch 34.69 | loss  4.48 | ppl    88.30
| epoch   6 |  3000/ 3263 batches | lr 5.00 | ms/batch 34.70 | loss  4.50 | ppl    89.92
| epoch   6 |  3200/ 3263 batches | lr 5.00 | ms/batch 34.69 | loss  4.42 | ppl    82.99
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 117.54s | valid loss  4.98 | valid ppl   145.94
-----------------------------------------------------------------------------------------
| epoch   7 |   200/ 3263 batches | lr 5.00 | ms/batch 35.70 | loss  4.61 | ppl   100.67
| epoch   7 |   400/ 3263 batches | lr 5.00 | ms/batch 35.54 | loss  4.62 | ppl   101.31
| epoch   7 |   600/ 3263 batches | lr 5.00 | ms/batch 35.55 | loss  4.51 | ppl    90.86
| epoch   7 |   800/ 3263 batches | lr 5.00 | ms/batch 35.53 | loss  4.44 | ppl    84.67
| epoch   7 |  1000/ 3263 batches | lr 5.00 | ms/batch 35.57 | loss  4.52 | ppl    92.23
| epoch   7 |  1200/ 3263 batches | lr 5.00 | ms/batch 35.54 | loss  4.46 | ppl    86.92
| epoch   7 |  1400/ 3263 batches | lr 5.00 | ms/batch 35.51 | loss  4.55 | ppl    95.04
| epoch   7 |  1600/ 3263 batches | lr 5.00 | ms/batch 35.50 | loss  4.50 | ppl    90.27
| epoch   7 |  1800/ 3263 batches | lr 5.00 | ms/batch 35.54 | loss  4.56 | ppl    96.03
| epoch   7 |  2000/ 3263 batches | lr 5.00 | ms/batch 35.54 | loss  4.49 | ppl    89.53
| epoch   7 |  2200/ 3263 batches | lr 5.00 | ms/batch 35.54 | loss  4.50 | ppl    89.88
| epoch   7 |  2400/ 3263 batches | lr 5.00 | ms/batch 35.53 | loss  4.38 | ppl    80.02
| epoch   7 |  2600/ 3263 batches | lr 5.00 | ms/batch 35.71 | loss  4.40 | ppl    81.57
| epoch   7 |  2800/ 3263 batches | lr 5.00 | ms/batch 35.77 | loss  4.42 | ppl    83.40
| epoch   7 |  3000/ 3263 batches | lr 5.00 | ms/batch 35.74 | loss  4.44 | ppl    85.16
| epoch   7 |  3200/ 3263 batches | lr 5.00 | ms/batch 35.80 | loss  4.37 | ppl    79.27
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 120.66s | valid loss  4.98 | valid ppl   144.81
-----------------------------------------------------------------------------------------
| epoch   8 |   200/ 3263 batches | lr 5.00 | ms/batch 34.81 | loss  4.54 | ppl    93.83
| epoch   8 |   400/ 3263 batches | lr 5.00 | ms/batch 34.66 | loss  4.55 | ppl    94.52
| epoch   8 |   600/ 3263 batches | lr 5.00 | ms/batch 34.65 | loss  4.44 | ppl    84.62
| epoch   8 |   800/ 3263 batches | lr 5.00 | ms/batch 34.64 | loss  4.38 | ppl    79.45
| epoch   8 |  1000/ 3263 batches | lr 5.00 | ms/batch 34.66 | loss  4.46 | ppl    86.88
| epoch   8 |  1200/ 3263 batches | lr 5.00 | ms/batch 34.64 | loss  4.41 | ppl    82.36
| epoch   8 |  1400/ 3263 batches | lr 5.00 | ms/batch 34.70 | loss  4.50 | ppl    89.92
| epoch   8 |  1600/ 3263 batches | lr 5.00 | ms/batch 34.71 | loss  4.45 | ppl    85.41
| epoch   8 |  1800/ 3263 batches | lr 5.00 | ms/batch 34.67 | loss  4.51 | ppl    91.10
| epoch   8 |  2000/ 3263 batches | lr 5.00 | ms/batch 34.70 | loss  4.45 | ppl    85.36
| epoch   8 |  2200/ 3263 batches | lr 5.00 | ms/batch 34.71 | loss  4.45 | ppl    85.50
| epoch   8 |  2400/ 3263 batches | lr 5.00 | ms/batch 34.68 | loss  4.33 | ppl    76.23
| epoch   8 |  2600/ 3263 batches | lr 5.00 | ms/batch 34.69 | loss  4.35 | ppl    77.61
| epoch   8 |  2800/ 3263 batches | lr 5.00 | ms/batch 34.65 | loss  4.37 | ppl    79.43
| epoch   8 |  3000/ 3263 batches | lr 5.00 | ms/batch 34.67 | loss  4.40 | ppl    81.22
| epoch   8 |  3200/ 3263 batches | lr 5.00 | ms/batch 34.72 | loss  4.33 | ppl    76.10
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 117.69s | valid loss  4.97 | valid ppl   144.14
-----------------------------------------------------------------------------------------
| epoch   9 |   200/ 3263 batches | lr 5.00 | ms/batch 34.88 | loss  4.48 | ppl    88.04
| epoch   9 |   400/ 3263 batches | lr 5.00 | ms/batch 34.68 | loss  4.49 | ppl    89.24
| epoch   9 |   600/ 3263 batches | lr 5.00 | ms/batch 34.73 | loss  4.39 | ppl    80.30
| epoch   9 |   800/ 3263 batches | lr 5.00 | ms/batch 34.76 | loss  4.32 | ppl    74.99
| epoch   9 |  1000/ 3263 batches | lr 5.00 | ms/batch 34.73 | loss  4.41 | ppl    82.55
| epoch   9 |  1200/ 3263 batches | lr 5.00 | ms/batch 34.74 | loss  4.36 | ppl    78.51
| epoch   9 |  1400/ 3263 batches | lr 5.00 | ms/batch 34.76 | loss  4.45 | ppl    85.54
| epoch   9 |  1600/ 3263 batches | lr 5.00 | ms/batch 34.76 | loss  4.40 | ppl    81.20
| epoch   9 |  1800/ 3263 batches | lr 5.00 | ms/batch 34.76 | loss  4.46 | ppl    86.81
| epoch   9 |  2000/ 3263 batches | lr 5.00 | ms/batch 34.77 | loss  4.40 | ppl    81.37
| epoch   9 |  2200/ 3263 batches | lr 5.00 | ms/batch 34.83 | loss  4.41 | ppl    82.03
| epoch   9 |  2400/ 3263 batches | lr 5.00 | ms/batch 34.75 | loss  4.29 | ppl    72.80
| epoch   9 |  2600/ 3263 batches | lr 5.00 | ms/batch 34.71 | loss  4.31 | ppl    74.41
| epoch   9 |  2800/ 3263 batches | lr 5.00 | ms/batch 34.74 | loss  4.33 | ppl    76.24
| epoch   9 |  3000/ 3263 batches | lr 5.00 | ms/batch 34.78 | loss  4.36 | ppl    77.89
| epoch   9 |  3200/ 3263 batches | lr 5.00 | ms/batch 34.80 | loss  4.29 | ppl    72.93
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 117.93s | valid loss  4.97 | valid ppl   143.56
-----------------------------------------------------------------------------------------
| epoch  10 |   200/ 3263 batches | lr 5.00 | ms/batch 34.95 | loss  4.43 | ppl    84.06
| epoch  10 |   400/ 3263 batches | lr 5.00 | ms/batch 34.84 | loss  4.44 | ppl    85.03
| epoch  10 |   600/ 3263 batches | lr 5.00 | ms/batch 34.83 | loss  4.34 | ppl    76.54
| epoch  10 |   800/ 3263 batches | lr 5.00 | ms/batch 34.77 | loss  4.28 | ppl    72.01
| epoch  10 |  1000/ 3263 batches | lr 5.00 | ms/batch 34.82 | loss  4.36 | ppl    78.62
| epoch  10 |  1200/ 3263 batches | lr 5.00 | ms/batch 34.86 | loss  4.32 | ppl    74.89
| epoch  10 |  1400/ 3263 batches | lr 5.00 | ms/batch 34.84 | loss  4.41 | ppl    81.86
| epoch  10 |  1600/ 3263 batches | lr 5.00 | ms/batch 34.84 | loss  4.36 | ppl    78.24
| epoch  10 |  1800/ 3263 batches | lr 5.00 | ms/batch 34.80 | loss  4.42 | ppl    83.23
| epoch  10 |  2000/ 3263 batches | lr 5.00 | ms/batch 34.80 | loss  4.36 | ppl    78.60
| epoch  10 |  2200/ 3263 batches | lr 5.00 | ms/batch 34.86 | loss  4.37 | ppl    78.92
| epoch  10 |  2400/ 3263 batches | lr 5.00 | ms/batch 34.87 | loss  4.25 | ppl    69.91
| epoch  10 |  2600/ 3263 batches | lr 5.00 | ms/batch 34.82 | loss  4.27 | ppl    71.64
| epoch  10 |  2800/ 3263 batches | lr 5.00 | ms/batch 34.79 | loss  4.30 | ppl    73.33
| epoch  10 |  3000/ 3263 batches | lr 5.00 | ms/batch 34.79 | loss  4.32 | ppl    75.14
| epoch  10 |  3200/ 3263 batches | lr 5.00 | ms/batch 34.84 | loss  4.25 | ppl    70.42
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 118.16s | valid loss  4.96 | valid ppl   142.91
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  4.89 | test ppl   133.24
=========================================================================================
